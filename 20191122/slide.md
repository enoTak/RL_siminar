<!-- slide -->
# Python深層学習入門

<!-- slide -->
## 強化学習の問題設定

- Agentが今の環境をみて行動選択($=
a$)
- 行動から結果($r$)が得られ
- 合わせて環境($s$)が変わる
- これを繰り返し、結果$r$の合計を最大化したい!!

<!-- slide -->

## 強化学習での言葉の定義

- "環境" = **状態**
- ""

<!-- slide -->

## Example

### ゲーム(Super Xxrio)をプレイする

- 自分 = Agent
- 今のゲーム画面・キャラのステータス = 環境
- キャラを操作 = 行動選択
- 結果、穴に落ちて体力減る = 報酬
- 次のゲーム画面・キャラのステータスに遷移する

<!-- slide -->

## 強化学習での基本プロシージャ

### 何を"強化"するの?

- "行動の選び方" = **方策**

1. 状態$S_t$からAgentが方策$\pi$に従い行動$A_t$を選択
1. 結果、報酬$R_{t+1}$が得られ、同時に状態が$S_{t+1}$に遷移
1. Agentは上で観測される$(S_t, A_t, R_{t+1})$から、$\pi$を$\pi'$に改善
1. これ繰り返し最適な$\pi$を求める

<!-- slide -->

## 考えるべきこと

- 何を持って最適というか? どう定量化するか?
- 観測からどう改善に結びつけるか?
- 観測をどうモデル化するか?
  - 環境から報酬が得られる手続きがわからないこともある!!

<!-- slide -->

## 以下学ぶこと

<!-- slide -->
## Markov過程とBellmann方程式


