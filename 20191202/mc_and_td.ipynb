{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward = np.zeros((3, 3, 2))\n",
    "reward[0, 1, 0] = 1.0\n",
    "reward[0, 2, 0] = 2.0\n",
    "reward[0, 0, 1] = 0.0\n",
    "reward[1, 0, 0] = 1.0\n",
    "reward[1, 2, 0] = 2.0\n",
    "reward[1, 1, 1] = 1.0\n",
    "reward[2, 0, 0] = 1.0\n",
    "reward[2, 1, 0] = 0.0\n",
    "reward[2, 2, 1] = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDP setting\n",
    "* state: index of each arrays\n",
    "  * 0: Home, 1: Office, 2: Bar\n",
    "* MDP array describes the probabilities for move to next state if choiced moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_prob = [0.8, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_state(current, next_prob_arr, unif):\n",
    "    next_prob = next_prob_arr[current]\n",
    "    if unif <= next_prob:\n",
    "        return (current + 1) % 3\n",
    "    else:\n",
    "        return (current + 2) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_state(0, transition_prob, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* move: 0, stay: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move = 0\n",
    "stay = 1\n",
    "def policy(state, p, unif):\n",
    "    move_prob = p[state]\n",
    "    if unif <= move_prob:\n",
    "        return move\n",
    "    else:\n",
    "        return stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = [0.5, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state: 0  action: 0  next state: 1  reward: 1.0\n",
      "current state: 1  action: 1  next state: 1  reward: 1.0\n",
      "current state: 1  action: 0  next state: 2  reward: 2.0\n",
      "current state: 2  action: 0  next state: 0  reward: 1.0\n",
      "current state: 0  action: 1  next state: 0  reward: 0.0\n",
      "current state: 0  action: 1  next state: 0  reward: 0.0\n",
      "current state: 0  action: 0  next state: 1  reward: 1.0\n",
      "current state: 1  action: 0  next state: 0  reward: 1.0\n",
      "current state: 0  action: 1  next state: 0  reward: 0.0\n",
      "current state: 0  action: 1  next state: 0  reward: 0.0\n"
     ]
    }
   ],
   "source": [
    "s = init_state\n",
    "a = 0\n",
    "r = 0.0\n",
    "state_hist = []\n",
    "action_hist = []\n",
    "reward_hist = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    unif = np.random.uniform()\n",
    "    a = policy(s, pi, unif)\n",
    "    \n",
    "    if a == move:\n",
    "        unif = np.random.uniform()\n",
    "        next_s = get_next_state(s, transition_prob, unif)\n",
    "    else:\n",
    "        next_s = s\n",
    "    \n",
    "    r = reward[s, next_s, a]\n",
    "    \n",
    "    state_hist.append(s)\n",
    "    action_hist.append(a)\n",
    "    reward_hist.append(r)\n",
    "    \n",
    "    print('current state:', s, ' action:', a, ' next state:', next_s, ' reward:', r)\n",
    "    \n",
    "    s = next_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 1, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 2.0, -1.0, -1.0, -1.0, -1.0, -1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def monte_carlo_by_episode(state_hist, reward_hist):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
